{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "colab": {
      "name": "3_data_preprocessing-emotion.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVWdUYfD7izz"
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import os\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOchvecF7iz3"
      },
      "source": [
        "# Face Detection Model\n",
        "- Load the models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amhFjiMR7iz5"
      },
      "source": [
        "face_detection_model = './models/res10_300x300_ssd_iter_140000.caffemodel'\n",
        "face_detection_proto = './models/deploy.prototxt.txt'\n",
        "face_descriptor = './models/openface.nn4.small2.v1.t7'\n",
        "# load models using cv2 dnn\n",
        "detector_model = cv2.dnn.readNetFromCaffe(face_detection_proto,face_detection_model)\n",
        "descriptor_model = cv2.dnn.readNetFromTorch(face_descriptor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-GkazP57iz7",
        "outputId": "2dd9f884-a6a9-42e7-9c2a-93d7239d245d"
      },
      "source": [
        "!dir emotion_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Volume in drive C is OS\n",
            " Volume Serial Number is 0047-2CB0\n",
            "\n",
            " Directory of C:\\Users\\atuld\\Desktop\\Face_Recognition\\5_Face_Recognition_MachineLearning\\emotion_data\n",
            "\n",
            "09-06-2021  11:59    <DIR>          .\n",
            "09-06-2021  11:59    <DIR>          ..\n",
            "09-06-2021  11:58    <DIR>          angry\n",
            "09-06-2021  11:58    <DIR>          disgust\n",
            "09-06-2021  11:58    <DIR>          fear\n",
            "09-06-2021  11:58    <DIR>          happy\n",
            "09-06-2021  11:59    <DIR>          neutral\n",
            "09-06-2021  11:59    <DIR>          sad\n",
            "09-06-2021  11:59    <DIR>          surprise\n",
            "               0 File(s)              0 bytes\n",
            "               9 Dir(s)  130,167,193,600 bytes free\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nX7WLYH7iz9"
      },
      "source": [
        "# consider sample image\n",
        "img = cv2.imread('./emotion_data/angry/0.jpg')\n",
        "cv2.imshow('sample',img)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtZkVrBw7iz-"
      },
      "source": [
        "def helper(image_path):\n",
        "    img = cv2.imread(image_path)\n",
        "    # step-1: face detection\n",
        "    image = img.copy()\n",
        "    h,w = image.shape[:2]\n",
        "    img_blob = cv2.dnn.blobFromImage(image,1,(300,300),(104,177,123),swapRB=False,crop=False)\n",
        "    # set the input\n",
        "    detector_model.setInput(img_blob)\n",
        "    detections = detector_model.forward()\n",
        "\n",
        "    if len(detections) > 0:\n",
        "        i = np.argmax(detections[0,0,:,2])# consider the face with max confidence score\n",
        "        confidence = detections[0,0,i,2]\n",
        "        if confidence > 0.5:\n",
        "            box = detections[0,0,i,3:7]*np.array([w,h,w,h])\n",
        "            (startx,starty,endx,endy) = box.astype('int')\n",
        "            # step-2: Feature Extraction or Embedding\n",
        "            roi = image[starty:endy,startx:endx].copy()\n",
        "            # get the face descriptors\n",
        "            faceblob = cv2.dnn.blobFromImage(roi,1/255,(96,96),(0,0,0),swapRB=True,crop=True)\n",
        "            descriptor_model.setInput(faceblob)\n",
        "            vectors = descriptor_model.forward()\n",
        "            \n",
        "            return vectors\n",
        "    return None\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frvJIgQ47iz-"
      },
      "source": [
        "# apply helper function to all images and get face descriptors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ombg0xyY7iz_"
      },
      "source": [
        "data = dict(data=[],label=[])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "PJC9Rur57i0B"
      },
      "source": [
        "folders = os.listdir('emotion_data')\n",
        "for folder in folders:\n",
        "    filenames = os.listdir('emotion_data/{}'.format(folder))\n",
        "    for filename in filenames:\n",
        "        try:\n",
        "\n",
        "            vector = helper('./emotion_data/{}/{}'.format(folder,filename))\n",
        "            if vector is not None:\n",
        "                data['data'].append(vector)\n",
        "                data['label'].append(folder)\n",
        "                print('Feature Extracted Sucessfully')\n",
        "                \n",
        "        except:\n",
        "            pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPXqxJCM7i0D",
        "outputId": "2d1eb9ee-6d2e-4acf-c352-efa051595f45"
      },
      "source": [
        "data.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['data', 'label'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1FkUTzH7i0E",
        "outputId": "4da3b005-4fcd-4aac-ff5f-c4f51e65e440"
      },
      "source": [
        "pd.Series(data['label']).value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "neutral     292\n",
              "sad         260\n",
              "happy       244\n",
              "fear        207\n",
              "angry       189\n",
              "surprise    181\n",
              "disgust      40\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r19ukrcb7i0F"
      },
      "source": [
        "# save the data\n",
        "pickle.dump(data,open('data_face_features_emotion.pickle',mode='wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBeYQ-cy7i0F"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiWoqKAf7i0G"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "we0TgyoG7i0H"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzvViFS17i0H"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRjXNbJh7i0H"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiTbVhhy7i0H"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUTR-Nvm7i0H"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_yCxrqS7i0I"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpmRBE6u7i0I"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTht0YdN7i0I"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JW9In6wR7i0I"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITpqKJNl7i0I"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3fiyIT27i0J"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaREA8lS7i0J"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlnJUlTL7i0J"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kF4CENbg7i0J"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXEvN0xV7i0K"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xU2IT8vg7i0K"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SemzAIlY7i0K"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1kug16e7i0K"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}